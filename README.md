# cybersec-mlops-pipeline

üöÄ **Pipeline MLOps para detecci√≥n de anomal√≠as en eventos de red**, basado en modelos no supervisados (Isolation Forest, LOF, OCSVM) y reglas Sigma simuladas. Dise√±ado para ejecutarse on‚Äëpremise y escalar f√°cilmente en Kubernetes (RKE2 + Helm). 100% Open Source.

---

## üìö Contenidos

- [üß© Arquitectura MLOps](#-arquitectura-mlops-del-sistema)
- [üìì Notebook de justificaci√≥n](#-notebooks)
- [‚öôÔ∏è Pipeline MLOps](#-estructura-del-proyecto)
- [üß† Scripts y l√≥gica ML](#-scripts-principales)
- [üñ•Ô∏è Aplicaci√≥n Streamlit](#-aplicaci√≥n-streamlit-visualizaci√≥n-de-anomal√≠as)
- [üöÄ Ejecuci√≥n y despliegue](#-c√≥mo-ejecutar)
- [üî≠ Trabajo futuro](#-siguientes-pasos)

---

## üéì Contexto acad√©mico y alcance del proyecto

Este repositorio corresponde al **Trabajo Fin de M√°ster (TFM)** del autor y documenta la evoluci√≥n completa del proyecto desde una fase exploratoria hasta una implementaci√≥n **MLOps end-to-end** ejecutada sobre Kubernetes.

El proyecto se estructura en **tres niveles complementarios**:

1. **Exploraci√≥n y justificaci√≥n del modelo** (notebooks)
2. **Aplicaci√≥n de detecci√≥n y visualizaci√≥n** (scripts + Streamlit)
3. **Pipeline MLOps batch automatizado** (Prefect + MinIO + PostgreSQL + Kubernetes)

Cada uno de estos niveles se conserva de forma expl√≠cita en el repositorio para mostrar tanto el razonamiento acad√©mico como la implementaci√≥n profesional.

---

## üß© Arquitectura MLOps del sistema

El proyecto implementa una **arquitectura MLOps batch end-to-end**, dise√±ada para ejecutarse completamente **dentro de un cl√∫ster Kubernetes**, sin dependencias del entorno local.

La arquitectura combina herramientas open-source ampliamente utilizadas en MLOps:

- **Prefect** ‚Üí orquestaci√≥n de flujos
- **MinIO** ‚Üí data lake y model registry
- **PostgreSQL** ‚Üí auditor√≠a y trazabilidad
- **Kubernetes (RKE2)** ‚Üí ejecuci√≥n desacoplada y reproducible

### üîÑ Flujo general

A alto nivel, el sistema sigue el siguiente ciclo:

1. **Ingesta de datos**
   - Generaci√≥n y validaci√≥n de eventos de red
   - Persistencia en MinIO (capa RAW)
   - Registro de metadatos en PostgreSQL

2. **Transformaci√≥n de datos**
   - Enriquecimiento y feature engineering
   - Persistencia en MinIO (capa SILVER)
   - Auditor√≠a de transformaci√≥n

3. **Entrenamiento del modelo**
   - Entrenamiento batch con Isolation Forest
   - Versionado del modelo en MinIO
   - Registro de par√°metros y volumen de datos

4. **Evaluaci√≥n**
   - Aplicaci√≥n del modelo sobre datos recientes
   - C√°lculo de m√©tricas agregadas
   - Almacenamiento de resultados y auditor√≠a

Todo el flujo se ejecuta de forma autom√°tica mediante un **Job de Kubernetes**, utilizando im√°genes Docker versionadas.

### üì¶ Gesti√≥n de artefactos

El sistema separa claramente cada tipo de artefacto:

- **RAW** ‚Üí datos ingeridos sin procesar
- **SILVER** ‚Üí datos transformados
- **MODELS** ‚Üí modelos entrenados
- **EVAL** ‚Üí resultados de evaluaci√≥n

Todos los artefactos se almacenan en MinIO, utilizando nombres versionados con timestamps para garantizar **reproducibilidad y trazabilidad**.

### üîç Observabilidad y auditor√≠a

Cada fase del pipeline registra eventos estructurados en PostgreSQL, permitiendo responder preguntas clave como:

- ¬øQu√© datos se usaron para entrenar un modelo?
- ¬øCu√°ndo se ejecut√≥ cada fase?
- ¬øCon qu√© par√°metros?
- ¬øQu√© m√©tricas se obtuvieron?

Esta capa de auditor√≠a es fundamental en entornos de **ciberseguridad**, donde la trazabilidad es un requisito cr√≠tico.

---

## üß© Arquitectura MLOps del sistema

Este proyecto implementa una **arquitectura MLOps end-to-end** para la detecci√≥n de anomal√≠as en eventos de red, dise√±ada bajo principios de:

- reproducibilidad
- desacoplamiento
- trazabilidad
- ejecuci√≥n en Kubernetes

El sistema cubre **todo el ciclo de vida del modelo**, desde la ingesta de datos hasta la evaluaci√≥n final, sin dependencias del entorno local.

---

### üèó Componentes principales

El sistema se compone de los siguientes bloques:

- **Notebooks**  
  Justificaci√≥n te√≥rica y experimental del enfoque (no productivos).

- **Pipeline MLOps (Prefect)**  
  Orquesta todo el flujo batch:
  - ingesta
  - transformaci√≥n
  - entrenamiento
  - evaluaci√≥n

- **MinIO**  
  Act√∫a como *data lake* y *model registry*:
  - RAW ‚Üí datos sin procesar
  - SILVER ‚Üí datos transformados
  - MODELS ‚Üí artefactos entrenados
  - EVAL ‚Üí resultados de evaluaci√≥n

- **PostgreSQL**  
  Almacena metadatos operacionales:
  - ejecuciones
  - datasets usados
  - par√°metros de entrenamiento
  - m√©tricas obtenidas

- **Kubernetes (RKE2)**  
  Ejecuta el pipeline como Jobs desacoplados, permitiendo escalado y aislamiento.

- **Aplicaci√≥n Streamlit**  
  Permite visualizar anomal√≠as detectadas y evaluar el comportamiento del modelo.

---

### üîÑ Flujo de alto nivel

1. Se generan o ingieren eventos de red
2. Los datos se validan y almacenan en la capa RAW (MinIO)
3. Se transforman y enriquecen (SILVER)
4. Se entrena un modelo Isolation Forest
5. El modelo se eval√∫a sobre datos recientes
6. Todos los pasos quedan auditados

Este dise√±o refleja un **pipeline MLOps realista**, alineado con pr√°cticas profesionales en entornos de ciberseguridad.

---


## üìì Notebooks

Los notebooks permiten explorar, probar y justificar el enfoque antes de desplegarlo como aplicaci√≥n. Funcionan como gu√≠a conceptual.

### `notebooks/deteccion_anomalias_explicado.ipynb`

Contiene:

- Simulaci√≥n y carga de eventos de red  
- Extracci√≥n de caracter√≠sticas (*features*)  
- Comparaci√≥n de modelos:
  - Isolation Forest ‚úÖ
  - Local Outlier Factor
  - One-Class SVM  
- M√©todos de evaluaci√≥n: TP, FP, score  
- Simulaci√≥n de correlaci√≥n con reglas Sigma  
- Justificaci√≥n del modelo final elegido  

> Este notebook **no se usa en producci√≥n**, pero **es clave para entender todo el dise√±o**.

---

## üìÅ Estructura del Proyecto

> ‚ö†Ô∏è **Nota sobre la estructura**
>
> Este repositorio incluye tanto:
>
> - c√≥digo exploratorio y scripts iniciales (fase de experimentaci√≥n)
> - como una implementaci√≥n completa de un pipeline MLOps productivo sobre Kubernetes
>
> Ambas partes se conservan deliberadamente:
> - los **scripts y notebooks** justifican decisiones t√©cnicas
> - el **pipeline Prefect + MinIO + PostgreSQL** representa la soluci√≥n final


```bash
cybersec-mlops-pipeline/
‚îú‚îÄ‚îÄ backend/                  # (Vac√≠o) Backend opcional para FastAPI
‚îú‚îÄ‚îÄ data/                     # Datos de entrada y salida
‚îÇ   ‚îú‚îÄ‚îÄ normalized/          # Dataset procesado en Parquet
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ zeek.parquet
‚îÇ   ‚îî‚îÄ‚îÄ alerts_ml.csv        # Alertas generadas por ML
‚îú‚îÄ‚îÄ docs/                     # Documentaci√≥n interna del proyecto
‚îÇ   ‚îú‚îÄ‚îÄ 01_objetivos.md
‚îÇ   ‚îú‚îÄ‚îÄ 02_metricas.md
‚îÇ   ‚îú‚îÄ‚îÄ 03_estructura.md
‚îÇ   ‚îú‚îÄ‚îÄ 04_scripts.md
‚îÇ   ‚îî‚îÄ‚îÄ 05_tests.md
‚îú‚îÄ‚îÄ frontend/                 # Interfaz web en Streamlit
‚îÇ   ‚îî‚îÄ‚îÄ streamlit_app.py
‚îú‚îÄ‚îÄ infra/                    # (Vac√≠o) Infraestructura para K8s, Helm, CI/CD
‚îú‚îÄ‚îÄ ml/                       # L√≥gica de entrenamiento y scoring
‚îÇ   ‚îú‚îÄ‚îÄ anomaly_detector.py
‚îÇ   ‚îî‚îÄ‚îÄ features.py
‚îú‚îÄ‚îÄ models/                   # Modelos entrenados
‚îÇ   ‚îî‚îÄ‚îÄ iforest.joblib
‚îú‚îÄ‚îÄ notebooks/                # Notebooks de an√°lisis
‚îÇ   ‚îî‚îÄ‚îÄ deteccion_anomalias_explicado.ipynb
‚îú‚îÄ‚îÄ rules/                    # Reglas Sigma simuladas
‚îÇ   ‚îî‚îÄ‚îÄ sigma_emulator.py
‚îú‚îÄ‚îÄ scripts/                  # Scripts ejecutables del pipeline
‚îÇ   ‚îú‚îÄ‚îÄ generate_test_parquet.py
‚îÇ   ‚îú‚îÄ‚îÄ run_iforest.py
‚îÇ   ‚îú‚îÄ‚îÄ run_pipeline.py
‚îÇ   ‚îú‚îÄ‚îÄ score_events.py
‚îÇ   ‚îî‚îÄ‚îÄ train_iforest.py
‚îú‚îÄ‚îÄ tests/                    # Tests unitarios
‚îÇ   ‚îî‚îÄ‚îÄ test_pipeline.py
‚îú‚îÄ‚îÄ Dockerfile                # Definici√≥n de imagen Docker
‚îú‚îÄ‚îÄ requirements.txt          # Dependencias del proyecto
‚îî‚îÄ‚îÄ README.md                 # Este archivo
```

### üß™ C√≥digo exploratorio y scripts legacy

Los siguientes directorios corresponden a fases iniciales del proyecto y se conservan como:

- evidencia de experimentaci√≥n
- apoyo conceptual

Incluyen:

- `scripts/` ‚Üí ejecuci√≥n local del pipeline inicial
- `ml/` ‚Üí l√≥gica base de entrenamiento y scoring
- `rules/` ‚Üí simulaci√≥n de reglas Sigma
- `tests/` ‚Üí pruebas unitarias b√°sicas

Este c√≥digo **no se ejecuta en producci√≥n**, pero es clave para entender la evoluci√≥n del sistema.

### üîÅ Pipeline MLOps productivo (Kubernetes)

La implementaci√≥n **productiva y automatizada** del sistema se encuentra en el directorio:

```bash
pipeline/
```

Este m√≥dulo representa la **fuente de verdad** del sistema y se ejecuta completamente dentro de Kubernetes mediante Jobs.

```text
pipeline/
‚îú‚îÄ‚îÄ full_mlops_flow.py        # Orquestador end-to-end
‚îú‚îÄ‚îÄ ingestion/                # Ingesta batch (RAW)
‚îú‚îÄ‚îÄ transformation/           # Feature engineering (SILVER)
‚îú‚îÄ‚îÄ training/                 # Entrenamiento del modelo
‚îú‚îÄ‚îÄ evaluation/               # Evaluaci√≥n del rendimiento
‚îî‚îÄ‚îÄ config/                   # Configuraci√≥n compartida
```

Cada subm√≥dulo incluye su propio README con explicaci√≥n t√©cnica detallada.

---

## üß† Scripts Principales

| Script                        | Descripci√≥n                                                         |
|------------------------------|---------------------------------------------------------------------|
| `scripts/train_iforest.py`   | Entrena y guarda el modelo Isolation Forest (`iforest.joblib`)      |
| `scripts/score_events.py`    | Punt√∫a eventos usando el modelo entrenado (`ml_score`)              |
| `scripts/run_iforest.py`     | Filtra outliers y genera alertas ML (`alerts_ml.csv`)               |
| `scripts/run_pipeline.py`    | Ejecuta toda la cadena (entrena ‚Üí punt√∫a ‚Üí alerta)                  |
| `scripts/generate_test_parquet.py` | Genera datos de prueba simulados en formato Parquet           |
| `rules/sigma_emulator.py`    | Simula reglas Sigma sobre eventos para correlaci√≥n b√°sica          |

---

## üñ•Ô∏è Aplicaci√≥n Streamlit: Visualizaci√≥n de Anomal√≠as

### üìå Decisi√≥n de modelo desplegado

En producci√≥n se utiliza exclusivamente el modelo **Isolation Forest**, por su:

- Rendimiento general equilibrado
- Interpretaci√≥n sencilla
- Integraci√≥n directa en la app

Los otros modelos (`LOF` y `OCSVM`) se pueden evaluar en la pesta√±a ‚ÄúEvaluaci√≥n‚Äù de la app pero **no** se despliegan como modelo productivo.

---

### üìä Qu√© muestra la aplicaci√≥n

- **Anomal√≠as ML** ‚Äî Alertas generadas por Isolation Forest.
- **Evaluaci√≥n** ‚Äî Comparaci√≥n de distribuci√≥n de score y comportamiento de distintos modelos.

---

## üöÄ C√≥mo Ejecutar el Proyecto

### ‚ôªÔ∏è Ejecuci√≥n local (fase exploratoria)

> ‚ö†Ô∏è Esta forma de ejecuci√≥n corresponde a una fase inicial del proyecto y se conserva con fines demostrativos y de aprendizaje.
>  
> El pipeline productivo se ejecuta exclusivamente en Kubernetes.

```bash
python3 scripts/run_pipeline.py
```

- Entrena Isolation Forest - Punt√∫a eventos - Genera alertas si corresponde - Resultados en data/alerts_ml.csv


### ‚ò∏Ô∏è Ejecuci√≥n MLOps en Kubernetes (recomendada)

La forma **principal y productiva** de ejecutar este proyecto es mediante un **Job de Kubernetes**, que lanza el pipeline completo end-to-end dentro del cl√∫ster.

Este enfoque garantiza:

- ejecuci√≥n reproducible
- aislamiento del entorno
- uso exclusivo de servicios internos (MinIO, PostgreSQL)
- ausencia de dependencias locales

#### ‚ñ∂Ô∏è Ejecutar el pipeline completo

```bash
kubectl apply -f infra/k8s/job-full-mlops.yaml
```
#### ‚ñ∂Ô∏è Ver el estado del Job

```bash
kubectl get jobs -n mlops
kubectl get pods -n mlops
```
#### ‚ñ∂Ô∏è Ver logs del pipeline


```bash
kubectl logs -n mlops job/full-mlops-pipeline
```

El Job ejecuta internamente:

- ingesta de datos

- transformaci√≥n

- entrenamiento

- evaluaci√≥n

Todo ello orquestado mediante **Prefect** y persistiendo artefactos en **MinIO**.

---

### üñ•Ô∏è Visualizaci√≥n (Streamlit)

La aplicaci√≥n Streamlit se utiliza √∫nicamente como **capa de visualizaci√≥n**, no como motor del pipeline MLOps.
---

### üêøÔ∏è Lanzar la app con Docker

```bash
docker build -t soc-copilot-app .
docker run -p 8501:8501 -v $(pwd)/data:/app/data soc-copilot-app
```

Accede a la app desde:

```
http://localhost:8501
```

---

## üî≠ Siguientes Pasos

Las siguientes l√≠neas de trabajo representan **extensiones naturales del sistema**, no requisitos para la validez del pipeline actual.

El alcance del proyecto se ha delimitado conscientemente para priorizar:
- robustez del pipeline batch
- trazabilidad
- reproducibilidad
- arquitectura MLOps sobre Kubernetes


### üß© Evoluci√≥n funcional

- [ ] Integrar correlaci√≥n real entre reglas Sigma y anomal√≠as ML
- [ ] Backend REST con FastAPI para serving offline
- [ ] Mejora de la l√≥gica de scoring y umbrales din√°micos

### ‚öôÔ∏è Evoluci√≥n MLOps

- [ ] Integraci√≥n de tracking de experimentos con MLflow
- [ ] Registro avanzado de m√©tricas y artefactos
- [ ] Monitorizaci√≥n con Prometheus + Grafana
- [ ] Automatizaci√≥n CI/CD con GitHub Actions
- [ ] Despliegue mediante Helm Charts

### üéì Extensi√≥n acad√©mica

- [ ] Evaluaci√≥n con datasets reales de ciberseguridad
- [ ] Comparativa formal con otros enfoques de detecci√≥n
- [ ] Validaci√≥n temporal del modelo (data drift / concept drift)

---

> Este repositorio refleja tanto la evoluci√≥n del proyecto como su arquitectura final, diferenciando claramente entre fases exploratorias y componentes productivos.
