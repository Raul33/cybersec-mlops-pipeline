# ğŸ§© Pipeline MLOps â€“ VisiÃ³n global

Este directorio contiene la implementaciÃ³n completa de un **pipeline MLOps end-to-end** para un sistema de detecciÃ³n de anomalÃ­as en eventos de red, diseÃ±ado para ejecutarse de forma **reproducible, trazable y desacoplada** sobre Kubernetes.

El pipeline automatiza todo el ciclo de vida del modelo, desde la ingesta de datos hasta la evaluaciÃ³n final, siguiendo principios de **ingenierÃ­a MLOps moderna**.

---

## ğŸ¯ Objetivo del pipeline

El objetivo principal del pipeline es:

- Automatizar el procesamiento de eventos de red
- Entrenar y evaluar un modelo de detecciÃ³n de anomalÃ­as
- Versionar datasets y modelos
- Registrar eventos clave para auditorÃ­a y trazabilidad
- Ejecutarse de forma controlada dentro de un clÃºster Kubernetes

Este pipeline estÃ¡ pensado para **entornos de ciberseguridad**, donde la reproducibilidad y la trazabilidad son crÃ­ticas.

---

## ğŸ”„ Flujo general del pipeline

El pipeline se compone de cuatro grandes fases, orquestadas de forma secuencial:

1. **Ingesta de datos**
2. **TransformaciÃ³n**
3. **Entrenamiento del modelo**
4. **EvaluaciÃ³n**

Cada fase estÃ¡ implementada como un **flow independiente de Prefect**, lo que permite:

- ReutilizaciÃ³n
- Aislamiento de responsabilidades
- Escalabilidad futura
- Observabilidad del proceso completo

---

## ğŸ§  Arquitectura lÃ³gica

A alto nivel, el pipeline sigue la siguiente lÃ³gica:

- **Prefect** actÃºa como orquestador del flujo completo
- **MinIO** se utiliza como data lake y model registry
- **PostgreSQL** almacena metadatos de ejecuciÃ³n
- **Kubernetes** ejecuta el pipeline como un Job desacoplado

Todo el pipeline puede ejecutarse sin dependencias locales, utilizando Ãºnicamente servicios internos del clÃºster.

---

## ğŸ“¦ Componentes principales

El pipeline estÃ¡ organizado en los siguientes mÃ³dulos:

```text
pipeline/
â”œâ”€â”€ full_mlops_flow.py        # Orquestador principal del pipeline
â”œâ”€â”€ ingestion/                # Ingesta de datos (RAW)
â”œâ”€â”€ transformation/           # TransformaciÃ³n y feature engineering (SILVER)
â”œâ”€â”€ training/                 # Entrenamiento del modelo
â”œâ”€â”€ evaluation/               # EvaluaciÃ³n del modelo
â””â”€â”€ config/                   # ConfiguraciÃ³n compartida (features, esquemas, etc.)
```

---

## ğŸ§  Rol de `full_mlops_flow.py`

El archivo `full_mlops_flow.py` actÃºa como **orquestador principal del pipeline MLOps**, conectando y ejecutando de forma secuencial todos los flows funcionales del sistema.

Este flow **no implementa lÃ³gica de negocio propia**, sino que reutiliza flows ya existentes, garantizando:

- separaciÃ³n de responsabilidades
- reutilizaciÃ³n de cÃ³digo
- trazabilidad completa end-to-end
- facilidad de mantenimiento

### ğŸ”„ Secuencia de ejecuciÃ³n

El pipeline completo se ejecuta en el siguiente orden:

1. **Ingesta de datos**  
   Ejecuta `data_ingestion_flow`  
   - genera eventos sintÃ©ticos
   - guarda datos RAW en MinIO
   - registra la ingesta en PostgreSQL

2. **TransformaciÃ³n de datos**  
   Ejecuta `data_transformation_flow`  
   - transforma datos RAW â†’ SILVER
   - sube datasets procesados a MinIO
   - registra auditorÃ­a en PostgreSQL

3. **Entrenamiento del modelo**  
   Ejecuta `model_training_flow`  
   - entrena Isolation Forest
   - versiona el modelo en MinIO
   - registra parÃ¡metros y metadata

4. **EvaluaciÃ³n del modelo**  
   Ejecuta `model_evaluation_flow`  
   - evalÃºa el modelo entrenado
   - almacena mÃ©tricas en MinIO
   - registra resultados en PostgreSQL

### â˜¸ï¸ EjecuciÃ³n en Kubernetes

Este flow se ejecuta como un **Job de Kubernetes**, utilizando una imagen Docker especÃ­fica del proyecto.

- No requiere intervenciÃ³n manual
- No depende de estado persistente local
- Se apoya exclusivamente en servicios internos del clÃºster

De esta forma, `full_mlops_flow.py` representa una **implementaciÃ³n realista de un pipeline MLOps batch productivo**, alineado con prÃ¡cticas industriales.
---

## ğŸ§­ Uso de Prefect como orquestador ligero

En este proyecto se utiliza **Prefect** como framework de orquestaciÃ³n de flujos, **sin desplegar Prefect Server ni Prefect Cloud**.

Esta decisiÃ³n es **intencionada y justificada**, y responde a los objetivos del proyecto.

### ğŸ§  Â¿Por quÃ© usar Prefect sin servidor?

Prefect permite ejecutar flows de dos formas:

- modo **orquestado centralizado** (Prefect Server / Cloud)
- modo **local o embebido** (flow execution engine)

En este pipeline se utiliza el segundo enfoque, lo que permite:

- definir flujos declarativos (`@flow`, `@task`)
- mantener trazabilidad estructurada por logs
- controlar dependencias entre tasks
- ejecutar todo dentro de Kubernetes como un Job estÃ¡ndar

sin introducir infraestructura adicional innecesaria.

### âš–ï¸ JustificaciÃ³n de diseÃ±o

No se utiliza Prefect Server porque:

- el pipeline se ejecuta como batch diario
- no se requieren reintentos distribuidos complejos
- no se necesita scheduling externo (lo aporta Kubernetes)
- no se requiere UI de orquestaciÃ³n para este alcance

Kubernetes ya actÃºa como **scheduler, aislador y runtime**, por lo que aÃ±adir Prefect Server duplicarÃ­a responsabilidades.

### ğŸ¯ Beneficios del enfoque adoptado

Este enfoque permite:

- mantener el pipeline **simple y robusto**
- reducir superficie operativa
- mejorar la reproducibilidad
- facilitar la evaluaciÃ³n acadÃ©mica
- evolucionar fÃ¡cilmente a Prefect Server si fuese necesario

El diseÃ±o demuestra que **MLOps no implica sobreingenierÃ­a**, sino decisiones coherentes con el caso de uso.
---

## ğŸ—„ï¸ Rol de PostgreSQL en el pipeline MLOps

En este pipeline, **PostgreSQL no se utiliza como base de datos de eventos ni como data lake**, sino exclusivamente como **repositorio de metadatos y auditorÃ­a** del ciclo de vida MLOps.

### ğŸ“Œ Â¿QuÃ© se almacena en PostgreSQL?

PostgreSQL registra Ãºnicamente informaciÃ³n estructurada sobre cada ejecuciÃ³n del pipeline, incluyendo:

- eventos de ingesta de datos
- transformaciones ejecutadas
- entrenamientos realizados
- evaluaciones completadas

Cada registro representa una **evidencia auditable** de una operaciÃ³n del pipeline.

### ğŸ“¦ Â¿QuÃ© NO se almacena en PostgreSQL?

PostgreSQL **no almacena**:

- datasets (RAW / SILVER)
- modelos entrenados
- artefactos de evaluaciÃ³n
- ficheros parquet o binarios

Todos los artefactos pesados se almacenan en **MinIO**, que actÃºa como data lake y model registry.

### ğŸ§  SeparaciÃ³n clara de responsabilidades

Esta separaciÃ³n responde a un principio fundamental de MLOps:

- **MinIO** â†’ datos y modelos versionados
- **PostgreSQL** â†’ metadatos, estado y trazabilidad
- **Prefect** â†’ orquestaciÃ³n del proceso
- **Kubernetes** â†’ ejecuciÃ³n y aislamiento

Gracias a este diseÃ±o, el pipeline es:

- escalable
- auditable
- fÃ¡cil de mantener
- alineado con arquitecturas MLOps reales

### ğŸ” Beneficio para trazabilidad y compliance

El uso de PostgreSQL permite responder preguntas crÃ­ticas como:

- Â¿CuÃ¡ndo se entrenÃ³ este modelo?
- Â¿Con quÃ© dataset?
- Â¿CuÃ¡ntos registros se usaron?
- Â¿QuÃ© mÃ©tricas obtuvo?
- Â¿FallÃ³ o fue exitoso?

Esto es especialmente relevante en **entornos de ciberseguridad**, donde la explicabilidad y la auditorÃ­a son requisitos clave.

---

## ğŸª£ Rol de MinIO como Data Lake y Model Registry

MinIO actÃºa como el **sistema de almacenamiento persistente principal** del pipeline MLOps, cumpliendo dos funciones crÃ­ticas:

- **Data Lake** para datasets versionados
- **Model Registry** para artefactos de machine learning

MinIO implementa una interfaz compatible con **Amazon S3**, lo que permite aplicar patrones estÃ¡ndar de almacenamiento utilizados en entornos industriales.

---

### ğŸ“Š OrganizaciÃ³n por capas (Data Lake)

Los datos y artefactos se organizan en buckets independientes que representan distintas capas del pipeline:

- **RAW** (`cybersec-ml-raw`)  
  Datos ingeridos sin procesar

- **SILVER** (`cybersec-ml-silver`)  
  Datos transformados y enriquecidos

- **MODELS** (`cybersec-ml-models`)  
  Modelos entrenados y versionados

- **EVAL** (`cybersec-ml-eval`)  
  Resultados de evaluaciÃ³n del modelo

Esta separaciÃ³n facilita:

- trazabilidad entre capas
- rollback de versiones
- reproducibilidad total del pipeline

---

### ğŸ§  MinIO como Model Registry ligero

En lugar de utilizar una soluciÃ³n compleja de model registry, MinIO se emplea como un **registro de modelos sencillo pero eficaz**, donde:

- cada modelo se guarda con un nombre versionado por timestamp
- los modelos son inmutables
- los modelos pueden ser recuperados por otros servicios (batch o serving)

Este enfoque es coherente con pipelines batch y entornos Kubernetes-first.

---

### ğŸ” Persistencia desacoplada del entorno de ejecuciÃ³n

El pipeline se ejecuta dentro de contenedores efÃ­meros en Kubernetes.  
Los archivos locales generados durante la ejecuciÃ³n:

- existen Ãºnicamente durante la vida del contenedor
- se utilizan como almacenamiento temporal
- se suben inmediatamente a MinIO

Esto garantiza que:

- el pipeline sea completamente reproducible
- no existan dependencias del entorno local
- el almacenamiento persistente estÃ© desacoplado del cÃ³mputo

---

### âš™ï¸ Ventajas frente a almacenamiento local

El uso de MinIO aporta:

- compatibilidad S3 estÃ¡ndar
- integraciÃ³n nativa con Kubernetes
- escalabilidad horizontal
- aislamiento entre ejecuciÃ³n y persistencia
- alineaciÃ³n con arquitecturas cloud-native

Gracias a esto, el pipeline puede ejecutarse Ã­ntegramente dentro del clÃºster sin acceso al sistema de archivos del host.

---

## â˜¸ï¸ EjecuciÃ³n del pipeline en Kubernetes

El pipeline MLOps se ejecuta **Ã­ntegramente dentro de un clÃºster Kubernetes**, utilizando un **Job** como unidad de ejecuciÃ³n.  
No existe dependencia alguna de ejecuciÃ³n local ni de servicios externos al clÃºster.

---

### ğŸ§  Modelo de ejecuciÃ³n

El flujo completo se ejecuta como:

- un contenedor efÃ­mero
- lanzado mediante un objeto `Job`
- que ejecuta el flow principal `full_mlops_flow.py`
- y finaliza automÃ¡ticamente al completar el pipeline

Este enfoque es ideal para pipelines **batch MLOps**, donde cada ejecuciÃ³n es independiente y reproducible.

---

### ğŸ“¦ Imagen Docker del pipeline

El pipeline se empaqueta en una imagen Docker especÃ­fica que contiene:

- Python 3.11
- dependencias del pipeline (`requirements.pipeline.txt`)
- cÃ³digo del directorio `pipeline/`

La imagen **no contiene datos persistentes** y se limita a ejecutar el pipeline end-to-end.

Ejemplo de imagen utilizada:

```text
rcabe005/cybersec-mlops-runner:latest
```

### ğŸ—‚ï¸ Job de Kubernetes

La ejecuciÃ³n se define mediante un manifiesto Kubernetes (Job) que:

- lanza un Ãºnico contenedor

- inyecta variables de entorno mediante Secrets

- no expone puertos

- no mantiene estado tras la finalizaciÃ³n

Archivo de referencia:

```text
infra/k8s/job-full-mlops.yaml
```

Este diseÃ±o garantiza:

- aislamiento por ejecuciÃ³n

- control total del ciclo de vida

- fÃ¡cil re-ejecuciÃ³n del pipeline

- integraciÃ³n natural con CI/CD

### ğŸ” GestiÃ³n de configuraciÃ³n y secretos

Las credenciales necesarias (MinIO, PostgreSQL, etc.):

- no se incluyen en la imagen Docker

- se inyectan mediante **Secrets de Kubernetes**

- se consumen como variables de entorno

Esto cumple con buenas prÃ¡cticas de seguridad y separaciÃ³n de responsabilidades.

### ğŸ” Reproducibilidad y limpieza automÃ¡tica

Cada ejecuciÃ³n del Job:

- comienza desde un entorno limpio

- descarga Ãºnicamente los artefactos necesarios desde MinIO

- genera nuevos artefactos versionados

- finaliza sin dejar estado residual en el nodo

Gracias a este enfoque:

- no existen efectos colaterales entre ejecuciones

- el pipeline es totalmente reproducible

- el sistema es escalable horizontalmente

### âœ… Ventajas del enfoque Job-based

- alineado con arquitecturas cloud-native

- evita servicios persistentes innecesarios

- simplifica el debugging y el control de versiones

- refleja escenarios reales de producciÃ³n batch

Este modelo constituye la base para futuras extensiones como:

- programaciÃ³n periÃ³dica (CronJob)

- integraciÃ³n CI/CD

- despliegue de inferencia online

---


## ğŸ“Œ Nota sobre los paths locales

En el contexto de este pipeline, los tÃ©rminos *local* o *ruta local* hacen referencia **exclusivamente al sistema de archivos del contenedor que ejecuta el Job en Kubernetes**, no al equipo del desarrollador.

Todos los paths como:

```text
data/ingested/
data/silver/
data/models/
data/eval/
```

existen Ãºnicamente **durante la ejecuciÃ³n del contenedor** y se utilizan como almacenamiento temporal antes de subir los artefactos a MinIO.

Esto garantiza que:

- el pipeline sea completamente reproducible

- no existan dependencias del entorno local

- el almacenamiento persistente estÃ© desacoplado (MinIO)

El pipeline puede ejecutarse Ã­ntegramente dentro del clÃºster sin acceso al sistema de archivos del host.

---

## ğŸ“Š GestiÃ³n de datos y modelos

El pipeline implementa una separaciÃ³n clara de capas:

- RAW: datos ingeridos sin procesar

- SILVER: datos transformados y listos para modelado

- MODELS: artefactos entrenados y versionados

- EVAL: resultados de evaluaciÃ³n

Todos los artefactos se almacenan en MinIO, con nombres versionados basados en timestamps para garantizar reproducibilidad.

---

## ğŸ§¾ Trazabilidad y auditorÃ­a

Cada ejecuciÃ³n del pipeline registra eventos clave en PostgreSQL, incluyendo:

- Ingestas realizadas

- Transformaciones aplicadas

- Entrenamientos ejecutados

- Evaluaciones completadas

Esto permite responder a preguntas como:

- Â¿QuÃ© datos se usaron para entrenar este modelo?

- Â¿CuÃ¡ndo se generÃ³?

- Â¿Con quÃ© parÃ¡metros?

- Â¿QuÃ© mÃ©tricas obtuvo?

---

## âš ï¸ Alcance y decisiones de diseÃ±o

Este pipeline no incluye todavÃ­a:

- Tracking avanzado con MLflow

- Serving online del modelo

- MonitorizaciÃ³n en tiempo real

Estas funcionalidades se consideran trabajo futuro, y se han excluido deliberadamente para mantener el foco en la robustez del pipeline batch, que es la base de cualquier sistema MLOps sÃ³lido.