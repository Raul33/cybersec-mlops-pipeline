# ğŸ§© Pipeline MLOps â€“ VisiÃ³n global

Este directorio contiene la implementaciÃ³n completa de un **pipeline MLOps end-to-end** para un sistema de detecciÃ³n de anomalÃ­as en eventos de red, diseÃ±ado para ejecutarse de forma **reproducible, trazable y desacoplada** sobre Kubernetes.

El pipeline automatiza todo el ciclo de vida del modelo, desde la ingesta de datos hasta la evaluaciÃ³n final, siguiendo principios de **ingenierÃ­a MLOps moderna**.

---

## ğŸ¯ Objetivo del pipeline

El objetivo principal del pipeline es:

- Automatizar el procesamiento de eventos de red
- Entrenar y evaluar un modelo de detecciÃ³n de anomalÃ­as
- Versionar datasets y modelos
- Registrar eventos clave para auditorÃ­a y trazabilidad
- Ejecutarse de forma controlada dentro de un clÃºster Kubernetes

Este pipeline estÃ¡ pensado para **entornos de ciberseguridad**, donde la reproducibilidad y la trazabilidad son crÃ­ticas.

---

## ğŸ”„ Flujo general del pipeline

El pipeline se compone de cuatro grandes fases, orquestadas de forma secuencial:

1. **Ingesta de datos**
2. **TransformaciÃ³n**
3. **Entrenamiento del modelo**
4. **EvaluaciÃ³n**

Cada fase estÃ¡ implementada como un **flow independiente de Prefect**, lo que permite:

- ReutilizaciÃ³n
- Aislamiento de responsabilidades
- Escalabilidad futura
- Observabilidad del proceso completo

---

## ğŸ§  Arquitectura lÃ³gica

A alto nivel, el pipeline sigue la siguiente lÃ³gica:

- **Prefect** actÃºa como orquestador del flujo completo
- **MinIO** se utiliza como data lake y model registry
- **PostgreSQL** almacena metadatos de ejecuciÃ³n
- **Kubernetes** ejecuta el pipeline como un Job desacoplado

Todo el pipeline puede ejecutarse sin dependencias locales, utilizando Ãºnicamente servicios internos del clÃºster.

---

## ğŸ“¦ Componentes principales

El pipeline estÃ¡ organizado en los siguientes mÃ³dulos:

```text
pipeline/
â”œâ”€â”€ full_mlops_flow.py        # Orquestador principal del pipeline
â”œâ”€â”€ ingestion/                # Ingesta de datos (RAW)
â”œâ”€â”€ transformation/           # TransformaciÃ³n y feature engineering (SILVER)
â”œâ”€â”€ training/                 # Entrenamiento del modelo
â”œâ”€â”€ evaluation/               # EvaluaciÃ³n del modelo
â””â”€â”€ config/                   # ConfiguraciÃ³n compartida (features, esquemas, etc.)
```

---

## ğŸ“Š GestiÃ³n de datos y modelos

El pipeline implementa una separaciÃ³n clara de capas:

- RAW: datos ingeridos sin procesar

- SILVER: datos transformados y listos para modelado

- MODELS: artefactos entrenados y versionados

- EVAL: resultados de evaluaciÃ³n

Todos los artefactos se almacenan en MinIO, con nombres versionados basados en timestamps para garantizar reproducibilidad.

---

## ğŸ§¾ Trazabilidad y auditorÃ­a

Cada ejecuciÃ³n del pipeline registra eventos clave en PostgreSQL, incluyendo:

- Ingestas realizadas

- Transformaciones aplicadas

- Entrenamientos ejecutados

- Evaluaciones completadas

Esto permite responder a preguntas como:

- Â¿QuÃ© datos se usaron para entrenar este modelo?

- Â¿CuÃ¡ndo se generÃ³?

- Â¿Con quÃ© parÃ¡metros?

- Â¿QuÃ© mÃ©tricas obtuvo?

---

## âš ï¸ Alcance y decisiones de diseÃ±o

Este pipeline no incluye todavÃ­a:

- Tracking avanzado con MLflow

- Serving online del modelo

- MonitorizaciÃ³n en tiempo real

Estas funcionalidades se consideran trabajo futuro, y se han excluido deliberadamente para mantener el foco en la robustez del pipeline batch, que es la base de cualquier sistema MLOps sÃ³lido.