# Ingesta de Datos â€“ Pipeline Batch Diaria

Este mÃ³dulo implementa el flujo de ingesta de datos sintÃ©ticos para el proyecto de detecciÃ³n de anomalÃ­as en eventos de red. La ingesta se ejecuta mediante **Prefect** y actÃºa como primera fase dentro del pipeline MLOps del sistema.

---

## ğŸ§± Estado actual del mÃ³dulo

âœ“ Entorno virtual Python 3.11 creado
âœ“ Dependencias reproducibles en `requirements.txt`
âœ“ Prefect funcionando correctamente
âœ“ Flow base ejecutable en local
âœ“ Trazabilidad desde logs Prefect
âœ”ï¸ GeneraciÃ³n sintÃ©tica de eventos de red  
âœ”ï¸ ValidaciÃ³n de esquema y contenido  
âœ”ï¸ SerializaciÃ³n en formato Parquet  
âœ”ï¸ Almacenamiento en MinIO (RAW layer)  
âœ”ï¸ Registro de metadatos en PostgreSQL  
âœ”ï¸ OrquestaciÃ³n completa mediante Prefect  
âœ”ï¸ EjecuciÃ³n automÃ¡tica en Kubernetes (Job)


---

## ğŸ“Œ MotivaciÃ³n tÃ©cnica

Se eligiÃ³ **Python 3.11** para asegurar compatibilidad con Prefect 2.14.x. La versiÃ³n 3.12 provoca errores en dependencias internas (especialmente `pendulum`), por lo que se reconstruyÃ³ el entorno virtual para garantizar:

* estabilidad
* reproducibilidad
* portabilidad
* coherencia acadÃ©mica

---

## ğŸ“¦ Dependencias clave

```
prefect==2.14.10
griffe==0.36.5
```

Estas versiones se fijaron por motivos de compatibilidad y reproducibilidad del pipeline.

> El resto de dependencias (pandas, numpy, minio, psycopg2-binary) se gestionan a nivel de imagen Docker y no se listan aquÃ­ para evitar duplicidades.

---


## ğŸ” Flujo de ingesta de datos (data_ingestion_flow)

El flujo de ingesta se implementa mediante **Prefect** y estÃ¡ diseÃ±ado para ejecutar una **ingesta batch diaria** de eventos de red sintÃ©ticos, garantizando calidad de datos, trazabilidad y versionado.

El flujo completo estÃ¡ definido en el archivo:

```bash
pipeline/ingestion/data_ingestion_flow.py
```

---


### ğŸ“Œ Objetivos del flujo

- Simular eventos de red realistas
- Validar la calidad de los datos generados
- Persistir los datos en formato Parquet (capa RAW)
- Almacenar los datos en MinIO (object storage)
- Registrar metadatos de la ingesta en PostgreSQL
- Proporcionar trazabilidad completa del proceso

---

### ğŸ§  DescripciÃ³n de tasks

#### 1ï¸âƒ£ `generate_synthetic_events`

Genera un conjunto de eventos de red sintÃ©ticos representados como un `DataFrame` de pandas.

**Campos generados:**
- `timestamp`
- `src_ip`
- `dst_ip`
- `bytes`
- `duration`
- `protocol`

Este enfoque evita dependencias de datos reales, facilita la reproducibilidad y es adecuado para entornos acadÃ©micos y de pruebas.

---

#### 2ï¸âƒ£ `validate_data`

Aplica validaciones bÃ¡sicas de calidad de datos:

- Verifica que el DataFrame no estÃ© vacÃ­o
- Comprueba la existencia de las columnas esperadas
- Detecta valores nulos

Este task actÃºa como un **data quality gate** que previene la propagaciÃ³n de datos corruptos al resto del pipeline.

---

#### 3ï¸âƒ£ `save_parquet`

Guarda los eventos generados en formato **Parquet**, utilizando un nombre versionado con timestamp UTC.

**Ruta de salida:**

```bash
data/ingested/network_events_<timestamp>.parquet
```


El formato Parquet permite:
- Almacenamiento eficiente
- Lectura columnar
- IntegraciÃ³n con herramientas analÃ­ticas y de ML

---

#### 4ï¸âƒ£ `upload_to_minio`

Sube el archivo Parquet generado al bucket **RAW** en MinIO.

- Las credenciales se gestionan mediante variables de entorno
- Se devuelve la URI del objeto almacenado (`s3://bucket/archivo`)
- Compatible con ejecuciÃ³n local y en Kubernetes

Este paso desacopla el almacenamiento de datos del sistema de archivos local.

---

#### 5ï¸âƒ£ `register_ingestion_event`

Registra metadatos de la ingesta en una base de datos PostgreSQL:

- Timestamp de ingesta
- Nombre del archivo
- Ruta en MinIO
- NÃºmero de registros procesados
- Estado del proceso

Este registro proporciona **trazabilidad, auditorÃ­a y observabilidad** del pipeline MLOps.

---

#### 6ï¸âƒ£ `print_dataframe`

Task auxiliar utilizada para mostrar una vista previa de los datos en los logs de ejecuciÃ³n.  
Es Ãºtil para depuraciÃ³n y validaciÃ³n visual durante el desarrollo.

---

### ğŸ”— OrquestaciÃ³n del flow

El flow `data_ingestion_flow` coordina la ejecuciÃ³n secuencial de los tasks, gestionando las dependencias entre ellos y devolviendo:

- Ruta local del archivo generado
- URI del objeto almacenado en MinIO

Este flow actÃºa como **primer bloque funcional** del pipeline MLOps completo.


## ğŸ— Estructura del mÃ³dulo

```
pipeline/
  ingestion/
    data_ingestion_flow.py
    README.md  â† este archivo
```

---

## â–¶ï¸ EjecuciÃ³n del flow local

1. Activar el entorno virtual

```bash
source .venv311/bin/activate
```

2. Ejecutar el flow

```
python pipeline/ingestion/data_ingestion_flow.py
```

3. Resultado esperado

```
Prefect estÃ¡ funcionando correctamente ğŸš€
```

AdemÃ¡s, se mostrarÃ¡ trazabilidad Prefect en terminal, incluyendo:

* creaciÃ³n del flow run
* ejecuciÃ³n de task
* estado final

Esto confirma que la infraestructura base estÃ¡ operativa.

> Nota: En producciÃ³n, este flow se ejecuta automÃ¡ticamente como un Job de Kubernetes dentro del clÃºster.

---

## ğŸ“Œ EvoluciÃ³n del mÃ³dulo

El mÃ³dulo ha evolucionado desde una ingesta local bÃ¡sica hasta una ingesta batch completamente automatizada, integrada en un pipeline MLOps ejecutado en Kubernetes.

Actualmente, la ingesta constituye la capa RAW del sistema y sirve como punto de entrada para las fases de transformaciÃ³n, entrenamiento y evaluaciÃ³n de modelos.


---


## ğŸ§ª GeneraciÃ³n sintÃ©tica

Se aÃ±adiÃ³ el task `generate_synthetic_events` para producir un DataFrame sintÃ©tico con 10 eventos de red. Este paso valida la capacidad del pipeline para:

- procesar datos estructurados en forma tabular
- generar contenido reproducible
- orquestar ejecuciÃ³n mediante Prefect
- devolver estructuras complejas entre tasks

Este es el primer bloque funcional real del pipeline y servirÃ¡ como base para:

- validaciÃ³n de datos
- serializaciÃ³n parquet
- almacenamiento en MinIO
- registro de metadatos

---

## ğŸ”— IntegraciÃ³n en el pipeline MLOps

Este flow se ejecuta como subflow dentro del pipeline completo definido en:

pipeline/full_mlops_flow.py

Su correcta ejecuciÃ³n es un prerrequisito para las siguientes fases:

- TransformaciÃ³n de datos (Silver layer)
- Entrenamiento del modelo
- EvaluaciÃ³n del rendimiento
- Registro de artefactos

De esta forma, la ingesta garantiza que todo el pipeline trabaje sobre datos validados, versionados y trazables.


