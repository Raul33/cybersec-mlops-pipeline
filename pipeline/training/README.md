# 08 â€” Entrenamiento ML (Isolation Forest) + auditorÃ­a en PostgreSQL

## ğŸ¯ Objetivo
Esta fase incorpora un modelo de detecciÃ³n de anomalÃ­as basado en **Isolation Forest**, entrenado diariamente sobre datos transformados (silver). Produce un modelo funcional, almacenable y reutilizable para inferencia.

---

## ğŸ“Œ Flujo funcional
1ï¸âƒ£ Cargar datos SILVER materializados en el workspace del Job de Kubernetes
2ï¸âƒ£ Entrenar Isolation Forest  
3ï¸âƒ£ Guardar el modelo como pickle  
4ï¸âƒ£ Subir el modelo a MinIO (gold/models)  
5ï¸âƒ£ Registrar el evento en PostgreSQL  

---

## ğŸ§  Nota sobre ejecuciÃ³n en Kubernetes

Aunque el pipeline se ejecuta completamente en Kubernetes, cada Job dispone de un sistema de archivos efÃ­mero donde se materializan los resultados intermedios de cada subflow.

El mÃ³dulo de entrenamiento consume directamente los datos SILVER generados previamente dentro del mismo Job, evitando descargas redundantes desde MinIO y manteniendo el pipeline como una unidad atÃ³mica de ejecuciÃ³n.
---

## ğŸ“ Estructura de archivos generados

### ğŸ“¦ Modelo entrenado
Se almacena dentro de MinIO:

```bash
s3://cybersec-ml-models/model_isoforest_<timestamp>.pkl
```
Ejemplo real:

```bash
s3://cybersec-ml-models/model_isoforest_20251220_183501.pkl
```

---

## ğŸ“Œ Variables de entorno requeridas

### para MinIO
```bash
export MINIO_ENDPOINT="localhost:9000"
export MINIO_ACCESS_KEY="<YOUR_USER>"
export MINIO_SECRET_KEY="<YOUR_PASSWORD>"
```

### para PostgreSQL

```bash
export PG_HOST="localhost"
export PG_PORT="5555"
export PG_USER="postgres"
export PG_PASSWORD="<YOUR_PASSWORD>"
export PG_DATABASE="mlops_db"
```
## ğŸ—„ï¸ Tabla PostgreSQL utilizada (training audit)


```sql
CREATE TABLE IF NOT EXISTS training_events (
    id SERIAL PRIMARY KEY,
    timestamp_entrenamiento TIMESTAMP NOT NULL,
    ruta_modelo TEXT NOT NULL,
    num_registros INTEGER NOT NULL,
    parametros TEXT NOT NULL,
    estado TEXT NOT NULL
);
```

Campos:

- timestamp_entrenamiento: fecha real de ejecuciÃ³n

- ruta_modelo: ubicaciÃ³n exacta del pickle en MinIO

- num_registros: nÂº efectivo de filas usadas en el entrenamiento

- parametros: hiperparÃ¡metros del modelo

- estado: SUCCESS / FAILED

## ğŸ“Œ HiperparÃ¡metros usados (simple y estable)

```python
IsolationForest(
    contamination="auto",
    random_state=42,
    n_estimators=100
)
```
JustificaciÃ³n:

- n_estimators=100 â†’ buen equilibrio entre precisiÃ³n y coste

- random_state=42 â†’ reproducibilidad

- contamination='auto' â†’ robusto sin tunning

## ğŸ§  Posibles mÃ©tricas derivables del score (trabajo futuro)

Tras el entrenamiento, el modelo produce un score medio y desviaciÃ³n estÃ¡ndar:

- score_mean: = media(score_anomalÃ­a)

- score_std: = varianza(score_anomalÃ­a)

Estas mÃ©tricas permiten validar estabilidad sin complicar el diseÃ±o.

> Actualmente estas mÃ©tricas no se calculan ni se persisten en el pipeline.
> Su inclusiÃ³n se plantea como una extensiÃ³n natural en futuras iteraciones, por ejemplo mediante integraciÃ³n con MLflow.


---

## ğŸ“Š Ejemplo de registro real en PostgreSQL

```text
 id |   timestamp_entrenamiento    |                   ruta_modelo                  | num_registros |                parametros                 | estado  
----+------------------------------+------------------------------------------------+---------------+-------------------------------------------+---------
  1 | 2025-12-20 18:35:01.403920   | s3://cybersec-ml-models/model_isoforest_2025â€¦ |           457 | {'n_estimators':100,'contamination':'auto'} | SUCCESS

```
---

## ğŸ“Œ GestiÃ³n de features

El entrenamiento utiliza exclusivamente las columnas definidas en:

pipeline/config/features.py

Esto garantiza coherencia total entre entrenamiento e inferencia, evita divergencias de esquema y facilita el mantenimiento del sistema.

