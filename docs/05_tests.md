# 05 ‚Äî Tests y validaci√≥n del sistema

## üìå Introducci√≥n

Este documento describe el enfoque seguido para la **validaci√≥n y pruebas** del proyecto `cybersec-mlops-pipeline`.

Dado el car√°cter **exploratorio, no supervisado y orientado a pipeline MLOps** del sistema, la estrategia de testing se centra en:

- validaci√≥n funcional de los flujos
- comprobaci√≥n de integraciones entre componentes
- verificaci√≥n de la correcta ejecuci√≥n end-to-end

m√°s que en tests unitarios exhaustivos de bajo nivel.

---

## üéØ Objetivo de la estrategia de testing

Los objetivos principales de las pruebas en este proyecto son:

- asegurar que el pipeline completo se ejecuta sin errores
- verificar que cada fase produce los artefactos esperados
- validar la correcta comunicaci√≥n entre servicios (Prefect, MinIO, PostgreSQL)
- garantizar la reproducibilidad del flujo

üìå En proyectos MLOps reales, el **testing de pipelines** tiene un enfoque diferente al testing cl√°sico de software.

---

## üß† Enfoque adoptado

La estrategia de validaci√≥n se basa en tres pilares:

### 1Ô∏è‚É£ Validaci√≥n funcional de flows Prefect

Cada m√≥dulo del pipeline (`ingestion`, `transformation`, `training`, `evaluation`) se ha probado de forma independiente verificando que:

- el flow se ejecuta correctamente
- no se producen errores de dependencia
- los artefactos se generan y almacenan correctamente

Esto se ha realizado mediante:
- ejecuci√≥n manual de cada flow
- inspecci√≥n de logs
- verificaci√≥n de resultados en MinIO y PostgreSQL

---

### 2Ô∏è‚É£ Validaci√≥n end-to-end del pipeline completo

El archivo:

```text
pipeline/full_mlops_flow.py
```

act√∫a como **test de integraci√≥n principal**, ya que ejecuta el pipeline completo en orden:

1. ingesta

2. transformaci√≥n

3. entrenamiento

4. evaluaci√≥n

Si este flow finaliza correctamente, se considera que el sistema es funcional.

### 3Ô∏è‚É£ Tests automatizados m√≠nimos

El proyecto incluye un test automatizado b√°sico en:

```text
tests/test_pipeline.py
```

Este test verifica:

- que los m√≥dulos del pipeline pueden importarse correctamente

- que la estructura general del proyecto es v√°lida

- que no existen errores sint√°cticos o dependencias rotas

üìå Este tipo de test es habitual en proyectos MLOps como smoke test inicial.


El archivo `tests/test_pipeline.py` valida el funcionamiento de las funciones principales del pipeline: extracci√≥n de caracter√≠sticas, entrenamiento del modelo y puntuaci√≥n de eventos.

### üìÑ `tests/test_pipeline.py`

```python
import pandas as pd
import pytest
from pathlib import Path

from ml.features import extract_features
from ml.anomaly_detector import train_iforest, score_iforest

# Ruta de test del parquet generado previamente
data_path = Path("data/normalized/zeek.parquet")

@pytest.mark.parametrize("path", [data_path])
def test_extract_features(path):
    df = pd.read_parquet(path)
    features = extract_features(df)
    assert not features.empty, "Las features no deber√≠an estar vac√≠as"
    assert isinstance(features, pd.DataFrame), "Debe retornar un DataFrame"

def test_train_and_score():
    df = pd.read_parquet(data_path)
    model, feature_cols = train_iforest(df, contamination=0.05)
    result = score_iforest(df, model, feature_cols)

    assert "ml_score" in result.columns, "Debe contener la columna 'ml_score'"
    assert "ml_is_outlier" in result.columns, "Debe contener la columna 'ml_is_outlier'"
    assert set(result["ml_is_outlier"].unique()).issubset({0, 1}), "Valores v√°lidos: 0 o 1"
    assert result["ml_score"].between(0, 1).all(), "Todos los scores deben estar entre 0 y 1"

```

----

## ‚ö†Ô∏è Por qu√© no hay tests unitarios exhaustivos

No se han incluido tests unitarios detallados para cada funci√≥n por las siguientes razones:

- el sistema trabaja con datos no supervisados

- no existe un ground truth real para validar salidas

- gran parte de la l√≥gica depende de servicios externos (MinIO, PostgreSQL)

- el valor principal est√° en el flujo completo, no en funciones aisladas

En este contexto, los tests unitarios cl√°sicos aportar√≠an poco valor pr√°ctico.

---

## üß™ Validaciones manuales realizadas

Durante el desarrollo se han realizado validaciones manuales como:

- comprobaci√≥n de buckets MinIO y artefactos generados

- inspecci√≥n de tablas de auditor√≠a en PostgreSQL

- revisi√≥n de logs de Prefect

- verificaci√≥n visual de resultados en la aplicaci√≥n Streamlit

Estas validaciones forman parte del **proceso real de desarrollo MLOps**.

---

## üöÄ Trabajo futuro en testing

Como posibles extensiones del sistema se plantean:

- tests de calidad de datos (data validation)

- tests de drift del modelo

- validaci√≥n autom√°tica de esquemas

- tests de rendimiento del pipeline

- integraci√≥n con herramientas como Great Expectations

Estas mejoras se consideran fuera del alcance actual del proyecto.

---

## üß† Conclusi√≥n

La estrategia de testing adoptada es coherente con:

- la naturaleza del problema (detecci√≥n de anomal√≠as)

- el enfoque MLOps del proyecto

- el uso de Kubernetes y pipelines batch

El sistema prioriza la robustez del flujo completo frente a pruebas unitarias tradicionales, aline√°ndose con pr√°cticas reales de MLOps en entornos productivos.
