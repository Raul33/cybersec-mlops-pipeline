# 07 ‚Äî Resultados del sistema MLOps de detecci√≥n de anomal√≠as

## üìå Introducci√≥n

Este cap√≠tulo presenta los **resultados obtenidos** tras la implementaci√≥n y ejecuci√≥n del sistema MLOps desarrollado para la detecci√≥n de anomal√≠as en eventos de red.

Los resultados se analizan desde una doble perspectiva:

- **Resultados del modelo de machine learning**
- **Resultados del pipeline MLOps end-to-end**

El objetivo no es √∫nicamente evaluar el rendimiento del modelo, sino demostrar la **validez, reproducibilidad y trazabilidad del sistema completo**, que constituye el n√∫cleo del proyecto.

---

## üß† Resultados del modelo de detecci√≥n de anomal√≠as

### üìä Modelo utilizado

El modelo finalmente integrado en el pipeline es **Isolation Forest**, seleccionado tras un an√°lisis comparativo realizado en el notebook exploratorio del proyecto.

Las razones principales de su elecci√≥n fueron:

- Buen equilibrio entre detecci√≥n de anomal√≠as y falsos positivos
- Robustez frente a ruido
- Baja necesidad de ajuste de hiperpar√°metros
- Adecuaci√≥n a contextos sin etiquetas (aprendizaje no supervisado)

---

### ‚öôÔ∏è Configuraci√≥n del modelo

El entrenamiento se realiza autom√°ticamente sobre los datos transformados (capa SILVER), utilizando las mismas columnas de entrada de forma consistente.

Configuraci√≥n principal:

- `n_estimators = 100`
- `contamination = auto`
- `random_state = 42`

Esta configuraci√≥n prioriza **estabilidad y reproducibilidad** frente a optimizaci√≥n agresiva.

---

### üìà Resultados de evaluaci√≥n

Dado que el sistema trabaja con **datos no etiquetados**, la evaluaci√≥n se basa en m√©tricas indirectas y de comportamiento:

- **Tasa de anomal√≠as detectadas**
- **Distribuci√≥n del score de anomal√≠a**
- **Estabilidad estad√≠stica del score**
- **Consistencia entre ejecuciones**

Estas m√©tricas permiten validar el comportamiento del modelo sin necesidad de ground truth expl√≠cito, lo cual es habitual en escenarios reales de ciberseguridad.

---

### üìä M√©tricas registradas

En cada ejecuci√≥n de la fase de evaluaci√≥n se registran, entre otras, las siguientes m√©tricas:

- `anomaly_rate`: proporci√≥n de eventos marcados como an√≥malos
- `score_mean`: media del score de anomal√≠a
- `score_std`: desviaci√≥n est√°ndar del score

Estas m√©tricas permiten detectar:

- cambios bruscos en el comportamiento del modelo
- posibles problemas de deriva de datos
- ejecuciones an√≥malas del pipeline

Los resultados de evaluaci√≥n se almacenan de forma versionada en MinIO (bucket `cybersec-ml-eval`) y quedan auditados en PostgreSQL.

---

## üîÅ Resultados del pipeline MLOps

### üß© Ejecuci√≥n end-to-end

El pipeline MLOps completo se ejecuta como un **Job de Kubernetes**, lanzando el flow principal `full_mlops_flow`.

Cada ejecuci√≥n completa incluye:

1. Ingesta de datos (RAW)
2. Transformaci√≥n y feature engineering (SILVER)
3. Entrenamiento del modelo
4. Evaluaci√≥n del modelo
5. Registro de metadatos y auditor√≠a

El pipeline se ejecuta correctamente sin dependencia del entorno local, utilizando √∫nicamente servicios internos del cl√∫ster.

---

### üì¶ Resultados de persistencia y versionado

Durante una ejecuci√≥n completa del pipeline se generan y almacenan los siguientes artefactos:

- Dataset RAW en MinIO (`cybersec-ml-raw`)
- Dataset transformado SILVER (`cybersec-ml-silver`)
- Modelo entrenado (`cybersec-ml-models`)
- Resultados de evaluaci√≥n (`cybersec-ml-eval`)

Todos los artefactos:

- est√°n versionados mediante timestamp
- son inmutables una vez generados
- pueden ser reproducidos a partir de los metadatos registrados

---

### üßæ Resultados de trazabilidad y auditor√≠a

Cada fase del pipeline genera un evento estructurado en PostgreSQL:

- `ingestion_events`
- `transformation_events`
- `training_events`
- `evaluation_events`

Esto permite reconstruir completamente una ejecuci√≥n y responder a preguntas clave como:

- qu√© datos se utilizaron
- qu√© modelo se entren√≥
- cu√°ndo se ejecut√≥ cada fase
- qu√© m√©tricas se obtuvieron

La combinaci√≥n de Prefect + PostgreSQL proporciona una **trazabilidad completa del ciclo de vida del modelo**.

---

## üñ•Ô∏è Resultados de la aplicaci√≥n de visualizaci√≥n

La aplicaci√≥n web desarrollada con **Streamlit (SOC Copilot)** permite visualizar de forma intuitiva los resultados del pipeline:

- modelos disponibles en MinIO
- resultados de evaluaci√≥n m√°s recientes
- distribuci√≥n de scores de anomal√≠a
- exploraci√≥n interactiva de eventos

La aplicaci√≥n consume directamente los artefactos generados por el pipeline, validando la **integraci√≥n entre backend MLOps y frontend de visualizaci√≥n**.

---

## ‚úÖ Evaluaci√≥n global de resultados

A partir de los resultados obtenidos, se concluye que:

- el pipeline MLOps es funcional y estable
- el modelo de detecci√≥n de anomal√≠as se comporta de forma coherente
- la arquitectura es reproducible y desacoplada
- la trazabilidad est√° garantizada en todas las fases
- el sistema es representativo de un entorno real de MLOps en ciberseguridad

El proyecto cumple as√≠ los objetivos planteados y valida la viabilidad de una arquitectura MLOps on-premise basada en Kubernetes.

---

## üìå Resumen de resultados clave

- ‚úî Pipeline end-to-end operativo en Kubernetes
- ‚úî Modelo no supervisado entrenado autom√°ticamente
- ‚úî Versionado completo de datos, modelos y m√©tricas
- ‚úî Auditor√≠a estructurada por ejecuci√≥n
- ‚úî Visualizaci√≥n funcional de resultados
- ‚úî Dise√±o alineado con buenas pr√°cticas MLOps

Estos resultados constituyen la base para las conclusiones finales del trabajo.
