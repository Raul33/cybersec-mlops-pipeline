# 04 â€” Scripts auxiliares y utilidades

## ğŸ“Œ IntroducciÃ³n

El directorio `scripts/` contiene **scripts auxiliares** utilizados durante las primeras fases del proyecto para:

- exploraciÃ³n rÃ¡pida
- pruebas locales
- validaciÃ³n de ideas
- prototipado del flujo ML

Estos scripts **no forman parte de la pipeline MLOps final en Kubernetes**, pero son fundamentales para entender **la evoluciÃ³n del proyecto** y la toma de decisiones tÃ©cnicas.

---

## ğŸ¯ Objetivo del directorio `scripts/`

Este directorio cumple un rol **experimental y formativo**, permitiendo:

- ejecutar pasos del pipeline de forma aislada
- validar la lÃ³gica de ML sin orquestaciÃ³n
- depurar problemas rÃ¡pidamente
- generar datos de prueba

ğŸ“Œ En proyectos reales de MLOps es habitual mantener este tipo de scripts fuera del pipeline productivo.

---

## ğŸ“‚ Estructura del directorio

```text
scripts/
â”œâ”€â”€ generate_test_parquet.py
â”œâ”€â”€ train_iforest.py
â”œâ”€â”€ score_events.py
â”œâ”€â”€ run_iforest.py
â””â”€â”€ run_pipeline.py
```
---


## ğŸ“œ DocumentaciÃ³n de Scripts del Proyecto

Este documento describe la funcionalidad de cada uno de los scripts contenidos en la carpeta `scripts/`. Cada uno cumple un rol dentro del flujo de detecciÃ³n de anomalÃ­as mediante aprendizaje automÃ¡tico.

> âš ï¸ **Nota sobre rutas y persistencia**
>
> Los paths de entrada y salida utilizados en estos scripts (`data/normalized`, `models/`, etc.)
> corresponden a una **fase temprana del proyecto**, previa a la adopciÃ³n de MinIO y Kubernetes.
>
> En la versiÃ³n final del sistema:
> - los datos se almacenan en MinIO (RAW / SILVER)
> - los modelos se versionan en MinIO (MODELS)
> - la ejecuciÃ³n se realiza mediante Prefect + Kubernetes
>
> Estos scripts se mantienen como referencia histÃ³rica y conceptual.

---

## `generate_test_parquet.py`

ğŸ”§ **FunciÃ³n**: Genera un archivo Parquet con datos de ejemplo simulados para pruebas.

ğŸ“¥ **Input**: No requiere entradas externas.

ğŸ“¤ **Output**: Crea `data/normalized/zeek.parquet`.

ğŸ§  **Uso principal**: Proporciona una base mÃ­nima de datos para entrenar y probar los modelos.

---

## `train_iforest.py`

ğŸ¤– **FunciÃ³n**: Entrena el modelo Isolation Forest usando los datos de entrada.

ğŸ“¥ **Input**: `data/normalized/zeek.parquet`

ğŸ“¤ **Output**: Modelo guardado en `models/iforest.joblib`

ğŸ§  **Uso principal**: Crear un modelo capaz de detectar anomalÃ­as basado en los eventos de red.

---

## `score_events.py`

ğŸ“Š **FunciÃ³n**: Usa el modelo entrenado para puntuar nuevos eventos con un `ml_score`.

ğŸ“¥ **Input**: 
- Modelo desde `models/iforest.joblib`
- Datos desde `data/normalized/zeek.parquet`

ğŸ“¤ **Output**: Archivo con resultados en `data/scored.csv`

ğŸ§  **Uso principal**: Evaluar eventos y asignarles una probabilidad de anÃ³malo.

---

## `run_iforest.py`

ğŸš¨ **FunciÃ³n**: Detecta alertas en base al `ml_score` y genera un archivo con las mÃ¡s relevantes.

ğŸ“¥ **Input**:
- Modelo: `models/iforest.joblib`
- Eventos: `data/normalized/zeek.parquet`

ğŸ“¤ **Output**: Alertas guardadas en `data/alerts_ml.csv`

ğŸ§  **Uso principal**: Simula un sistema de detecciÃ³n de intrusiones que reporta las anomalÃ­as mÃ¡s crÃ­ticas.

---

## `run_pipeline.py`

âš™ï¸ **FunciÃ³n**: Ejecuta los scripts anteriores en orden para automatizar todo el flujo de trabajo.

ğŸ”— **Incluye**:
1. Entrenamiento del modelo (`train_iforest.py`)
2. PuntuaciÃ³n de eventos (`score_events.py`)
3. GeneraciÃ³n de alertas (`run_iforest.py`)

ğŸ§  **Uso principal**: Automatizar el flujo de entrenamiento, evaluaciÃ³n y generaciÃ³n de alertas con un solo comando.

```bash
python3 scripts/run_pipeline.py
```

---

## ğŸ§  ConclusiÃ³n

El directorio `scripts/` representa la **fase exploratoria y de validaciÃ³n inicial** del proyecto.
Aunque no forma parte del pipeline MLOps productivo, resulta clave para entender:

- la evoluciÃ³n del diseÃ±o
- las decisiones tÃ©cnicas adoptadas
- la transiciÃ³n hacia una arquitectura MLOps moderna
