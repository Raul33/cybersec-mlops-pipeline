# 06 â€” Ingesta y almacenamiento en MinIO (RAW layer)

## ğŸ“Œ IntroducciÃ³n

Este documento describe el uso de **MinIO** como sistema de almacenamiento de objetos dentro del proyecto `cybersec-mlops-pipeline`.

MinIO actÃºa como **data lake on-premise**, permitiendo almacenar datasets y artefactos de machine learning de forma:

- desacoplada
- versionada
- reproducible
- compatible con Kubernetes

En el pipeline MLOps, MinIO es el **punto central de persistencia de datos**.

---

## ğŸ¯ Objetivo de MinIO en el proyecto

MinIO se utiliza para cumplir los siguientes objetivos:

- almacenar datasets en distintas capas (RAW, SILVER, MODELS, EVAL)
- desacoplar el pipeline del sistema de archivos local
- permitir ejecuciÃ³n 100% dentro del clÃºster Kubernetes
- facilitar trazabilidad y versionado de artefactos
- simular un data lake real en entornos on-premise

ğŸ“Œ MinIO es completamente compatible con la API S3, lo que lo hace estÃ¡ndar en proyectos MLOps modernos.

---

## ğŸ§± Capas de almacenamiento definidas

El proyecto implementa una separaciÃ³n clara por buckets:

```text
cybersec-ml-raw       â†’ datos ingeridos sin procesar
cybersec-ml-silver    â†’ datos transformados
cybersec-ml-models    â†’ modelos entrenados
cybersec-ml-eval      â†’ resultados de evaluaciÃ³n
```

Esta separaciÃ³n facilita:

- control del ciclo de vida de los datos

- auditorÃ­a

- rollback

- reutilizaciÃ³n de artefactos

## ğŸ” Flujo de ingesta hacia MinIO

Durante la fase de ingesta:

1. Se generan eventos de red sintÃ©ticos

2. Se validan los datos

3. Se serializan en formato Parquet

4. Se suben al bucket RAW (`cybersec-ml-raw`)

El archivo queda almacenado con un nombre versionado basado en timestamp:

```text
network_events_<YYYYMMDD_HHMMSS>.parquet
```

---

## ğŸ§  ImplementaciÃ³n tÃ©cnica

La lÃ³gica de ingesta en MinIO se implementa en el task:

```text
upload_to_minio()
```

upload_to_minio()

```text
pipeline/ingestion/data_ingestion_flow.py
```

Este task:

- inicializa un cliente MinIO usando variables de entorno

- sube el archivo Parquet al bucket RAW

- devuelve la URI completa del objeto (`s3://bucket/archivo`)

---

## ğŸ“¦ Formato de datos: Parquet

Se utiliza el formato **Parquet** por los siguientes motivos:

- almacenamiento columnar eficiente

- compresiÃ³n automÃ¡tica

- lectura rÃ¡pida

- integraciÃ³n natural con pandas, Spark y ML

estÃ¡ndar en pipelines de datos modernos

ğŸ“Œ Esto facilita una transiciÃ³n futura a sistemas de big data si fuese necesario.

---

## ğŸ§¾ Trazabilidad y auditorÃ­a

Cada ingesta registrada en MinIO genera un evento de auditorÃ­a en PostgreSQL que incluye:

- timestamp de ingesta

- nombre del archivo

- ruta exacta en MinIO

- nÃºmero de registros

- estado de la ejecuciÃ³n

Esto permite responder preguntas como:

- Â¿quÃ© dataset se usÃ³?

- Â¿cuÃ¡ndo se generÃ³?

- Â¿dÃ³nde estÃ¡ almacenado?

- Â¿cuÃ¡ntos registros contiene?

---

## âš™ï¸ EjecuciÃ³n en Kubernetes

Cuando el pipeline se ejecuta en Kubernetes:

- los archivos locales existen solo dentro del contenedor

- MinIO actÃºa como almacenamiento persistente

- no se depende del filesystem del host

- la ejecuciÃ³n es completamente reproducible

ğŸ“Œ Este diseÃ±o es clave para entornos productivos.

---

## ğŸ§ª ValidaciÃ³n manual

Durante el desarrollo se validÃ³ la ingesta en MinIO mediante:

- inspecciÃ³n de buckets desde la UI de MinIO

- verificaciÃ³n de nombres y timestamps

- descarga manual de Parquets

- comparaciÃ³n con registros de PostgreSQL

---

## ğŸš€ Trabajo futuro

Posibles mejoras relacionadas con MinIO:

- polÃ­ticas de retenciÃ³n por bucket

- versionado automÃ¡tico de objetos

- cifrado en reposo

- integraciÃ³n con MLflow

- lifecycle management

Estas mejoras se consideran fuera del alcance actual del proyecto.

---

## ğŸ“Œ TecnologÃ­as usadas
- Prefect 2.14.10 â†’ orquestaciÃ³n  
- MinIO â†’ almacenamiento raw tipo S3 en Kubernetes  
- PostgreSQL â†’ metadata y auditorÃ­a de ingestas  
- Python 3.11 â†’ ejecuciÃ³n del pipeline  
- Parquet + PyArrow â†’ formato columna eficiente  
- Kubernetes â†’ entorno on-premises reproducible  

---

## ğŸ“ Estructura de archivos generados
Los datos quedan almacenados bajo:

```text
data/ingested/network_events_<timestamp>.parquet
```
ejemplo real:

```text
data/ingested/network_events_20251220_121209.parquet
```

## ğŸ“¦ Flujo funcional

1ï¸âƒ£ GeneraciÃ³n de dataset sintÃ©tico

- Cada ejecuciÃ³n produce 10 filas simuladas con campos:
timestamp, src_ip, dst_ip, bytes, duration, protocol

2ï¸âƒ£ ValidaciÃ³n estructural

- Tipos correctos

- Sin nulos

- Esquema consistente

3ï¸âƒ£ Persistencia local

- Guardado automÃ¡tico en parquet

4ï¸âƒ£ Carga a MinIO (S3)

- Bucket: cybersec-ml-raw

- Cada ingesta genera un objeto nuevo

5ï¸âƒ£ Registro operacional en PostgreSQL

- InserciÃ³n de un registro por ejecuciÃ³n

- AuditorÃ­a completa de origen, volumen y estado

---

## ğŸ§  ConclusiÃ³n

MinIO cumple un papel central en el pipeline MLOps, proporcionando un **data lake ligero, reproducible y alineado con buenas prÃ¡cticas**.

Su uso permite desacoplar completamente el procesamiento del almacenamiento, facilitando escalabilidad, auditorÃ­a y mantenimiento del sistema.




