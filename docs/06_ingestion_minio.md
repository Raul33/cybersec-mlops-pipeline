# 06 â€” Ingesta y almacenamiento en MinIO (RAW layer)

## ğŸ“Œ IntroducciÃ³n

Este documento describe el uso de **MinIO** como sistema de almacenamiento de objetos dentro del proyecto `cybersec-mlops-pipeline`.

MinIO actÃºa como **data lake on-premise**, permitiendo almacenar datasets y artefactos de machine learning de forma:

- desacoplada
- versionada
- reproducible
- compatible con Kubernetes

En el pipeline MLOps, MinIO es el **punto central de persistencia de datos**.

---

## ğŸ¯ Objetivo de MinIO en el proyecto

MinIO se utiliza para cumplir los siguientes objetivos:

- almacenar datasets en distintas capas (RAW, SILVER, MODELS, EVAL)
- desacoplar el pipeline del sistema de archivos local
- permitir ejecuciÃ³n 100% dentro del clÃºster Kubernetes
- facilitar trazabilidad y versionado de artefactos
- simular un data lake real en entornos on-premise

ğŸ“Œ MinIO es completamente compatible con la API S3, lo que lo hace estÃ¡ndar en proyectos MLOps modernos.

---

## ğŸ§± Capas de almacenamiento definidas

El proyecto implementa una separaciÃ³n clara por buckets:

```text
cybersec-ml-raw       â†’ datos ingeridos sin procesar
cybersec-ml-silver    â†’ datos transformados
cybersec-ml-models    â†’ modelos entrenados
cybersec-ml-eval      â†’ resultados de evaluaciÃ³n
```

Esta separaciÃ³n facilita:

- control del ciclo de vida de los datos

- auditorÃ­a

- rollback

- reutilizaciÃ³n de artefactos

## ğŸ” Flujo de ingesta hacia MinIO

Durante la fase de ingesta:

1. Se generan eventos de red sintÃ©ticos

2. Se validan los datos

3. Se serializan en formato Parquet

4. Se suben al bucket RAW (`cybersec-ml-raw`)

El archivo queda almacenado con un nombre versionado basado en timestamp:

```text
network_events_<YYYYMMDD_HHMMSS>.parquet
```

---

## ğŸ§  ImplementaciÃ³n tÃ©cnica

La lÃ³gica de ingesta en MinIO se implementa en el task:

```text
upload_to_minio()
```

upload_to_minio()

```text
pipeline/ingestion/data_ingestion_flow.py
```

Este task:

- inicializa un cliente MinIO usando variables de entorno

- sube el archivo Parquet al bucket RAW

- devuelve la URI completa del objeto (`s3://bucket/archivo`)

---

## ğŸ“¦ Formato de datos: Parquet

Se utiliza el formato **Parquet** por los siguientes motivos:

- almacenamiento columnar eficiente

- compresiÃ³n automÃ¡tica

- lectura rÃ¡pida

- integraciÃ³n natural con pandas, Spark y ML

estÃ¡ndar en pipelines de datos modernos

ğŸ“Œ Esto facilita una transiciÃ³n futura a sistemas de big data si fuese necesario.

---

## ğŸ§¾ Trazabilidad y auditorÃ­a

Cada ingesta registrada en MinIO genera un evento de auditorÃ­a en PostgreSQL que incluye:

- timestamp de ingesta

- nombre del archivo

- ruta exacta en MinIO

- nÃºmero de registros

- estado de la ejecuciÃ³n

Esto permite responder preguntas como:

- Â¿quÃ© dataset se usÃ³?

- Â¿cuÃ¡ndo se generÃ³?

- Â¿dÃ³nde estÃ¡ almacenado?

- Â¿cuÃ¡ntos registros contiene?

---

## âš™ï¸ EjecuciÃ³n en Kubernetes

Cuando el pipeline se ejecuta en Kubernetes:

- los archivos locales existen solo dentro del contenedor

- MinIO actÃºa como almacenamiento persistente

- no se depende del filesystem del host

- la ejecuciÃ³n es completamente reproducible

ğŸ“Œ Este diseÃ±o es clave para entornos productivos.

---

## ğŸ§ª ValidaciÃ³n manual

Durante el desarrollo se validÃ³ la ingesta en MinIO mediante:

- inspecciÃ³n de buckets desde la UI de MinIO

- verificaciÃ³n de nombres y timestamps

- descarga manual de Parquets

- comparaciÃ³n con registros de PostgreSQL

---

## ğŸš€ Trabajo futuro

Posibles mejoras relacionadas con MinIO:

- polÃ­ticas de retenciÃ³n por bucket

- versionado automÃ¡tico de objetos

- cifrado en reposo

- integraciÃ³n con MLflow

- lifecycle management

Estas mejoras se consideran fuera del alcance actual del proyecto.

---


###############################

## ğŸ“Œ Objetivo
En esta fase se implementa la ingesta de datos en modo batch diario, con:

- GeneraciÃ³n sintÃ©tica de trÃ¡fico de red  
- ValidaciÃ³n bÃ¡sica del dataset  
- Persistencia en formato parquet  
- Subida a MinIO (S3 on-premises)  
- Registro operacional en PostgreSQL  

Esta fase consolida el primer tramo real del pipeline MLOps orientado a detecciÃ³n de anomalÃ­as en red.

---

## ğŸ“Œ TecnologÃ­as usadas
- Prefect 2.14.10 â†’ orquestaciÃ³n  
- MinIO â†’ almacenamiento raw tipo S3 en Kubernetes  
- PostgreSQL â†’ metadata y auditorÃ­a de ingestas  
- Python 3.11 â†’ ejecuciÃ³n del pipeline  
- Parquet + PyArrow â†’ formato columna eficiente  
- Kubernetes â†’ entorno on-premises reproducible  

---

## ğŸ“ Estructura de archivos generados
Los datos quedan almacenados bajo:

```text
data/ingested/network_events_<timestamp>.parquet
```
ejemplo real:

```text
data/ingested/network_events_20251220_121209.parquet
```

## ğŸ“¦ Flujo funcional

1ï¸âƒ£ GeneraciÃ³n de dataset sintÃ©tico

- Cada ejecuciÃ³n produce 10 filas simuladas con campos:
timestamp, src_ip, dst_ip, bytes, duration, protocol

2ï¸âƒ£ ValidaciÃ³n estructural

- Tipos correctos

- Sin nulos

- Esquema consistente

3ï¸âƒ£ Persistencia local

- Guardado automÃ¡tico en parquet

4ï¸âƒ£ Carga a MinIO (S3)

- Bucket: cybersec-ml-raw

- Cada ingesta genera un objeto nuevo

5ï¸âƒ£ Registro operacional en PostgreSQL

- InserciÃ³n de un registro por ejecuciÃ³n

- AuditorÃ­a completa de origen, volumen y estado

## ğŸ“Œ Variables de entorno requeridas

Antes de ejecutar el pipeline, deben configurarse:

```bash
export MINIO_ENDPOINT="localhost:9000"
export MINIO_ACCESS_KEY="<YOUR_USER>"
export MINIO_SECRET_KEY="<YOUR_PASSWORD>"
```

> NOTA: El puerto 9000 es el API S3.
> El puerto 9001 es la consola web y no acepta operaciones S3.


```bash
kubectl port-forward pod/<NOMBRE_DEL_POD> -n mlops 9000:9000 9001:9001
```
PostgreSQL

```bash
export PG_HOST="localhost"
export PG_PORT="5555"
export PG_USER="postgres"
export PG_PASSWORD="<YOUR_PASSWORD>"
export PG_DATABASE="mlops_db"
```

> âš ï¸ PG_PASSWORD es obligatorio â€” si falta, el pipeline lo bloquea.

Para exponer PostgreSQL desde Kubernetes:

```bash
kubectl port-forward \
  -n mlops \
  svc/mlops-postgresql \
  5555:5432
```

## ğŸ—„ï¸ Tabla PostgreSQL utilizada

```sql
CREATE TABLE ingestion_events (
    id SERIAL PRIMARY KEY,
    timestamp_ingesta TIMESTAMP NOT NULL,
    nombre_archivo TEXT NOT NULL,
    ruta_minio TEXT NOT NULL,
    num_registros INTEGER NOT NULL,
    estado TEXT NOT NULL
);
```

## ğŸ“Œ Consulta rÃ¡pida de ingestiones histÃ³ricas

```bash
kubectl exec -it mlops-postgresql-0 -n mlops -- \
  psql -U postgres mlops_db \
  -c "SELECT * FROM ingestion_events ORDER BY id DESC LIMIT 10;"
```

Ejemplo de salida real:

```bash
 id |     timestamp_ingesta      |             nombre_archivo             |                         ruta_minio                          | num_registros | estado  
----+----------------------------+----------------------------------------+-------------------------------------------------------------+---------------+---------
  1 | 2025-12-20 12:12:09.495903 | network_events_20251220_121209.parquet | s3://cybersec-ml-raw/network_events_20251220_121209.parquet |            10 | SUCCESS
```

---

## ğŸ§  ConclusiÃ³n

MinIO cumple un papel central en el pipeline MLOps, proporcionando un **data lake ligero, reproducible y alineado con buenas prÃ¡cticas**.

Su uso permite desacoplar completamente el procesamiento del almacenamiento, facilitando escalabilidad, auditorÃ­a y mantenimiento del sistema.




